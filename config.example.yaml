# Toolify Configuration Example File
# Please copy this file as config.yaml and modify the configuration according to your actual needs

# Server configuration
server:
  port: 8000                    # Server listening port
  host: "0.0.0.0"              # Server listening address
  timeout: 180                  # Request timeout (seconds)

# Upstream OpenAI compatible service configuration
upstream_services:
  - name: "openai-primary"
    service_type: "openai"  # Service type: openai, anthropic, gemini
    base_url: "https://api.openai.com/v1"
    api_key: "your-openai-api-key-here"
    description: "OpenAI Official Service"
    is_default: true  # Deprecated field, use priority instead
    priority: 100  # Priority level (higher number = higher priority)
    inject_function_calling: null  # null = inherit from global setting, true = force enable, false = force disable
    model_mapping: {}  # Model redirect: client request model -> actual upstream model (e.g., gpt-4: gpt-4o)
    models:
      - "gpt-3.5-turbo"
      - "gpt-3.5-turbo-16k"
      - "gpt-4"
      - "gpt-4-turbo"
      - "gpt-4o"
      - "gpt-4o-mini"

  - name: "openai-backup"
    service_type: "openai"
    base_url: "https://api.openai-proxy.com/v1"
    api_key: "your-backup-api-key-here"
    description: "OpenAI Backup Service (fallback)"
    is_default: false
    priority: 50  # Backup channel with lower priority
    models:
      - "gpt-4"
      - "gpt-4o"

  - name: "anthropic-claude"
    service_type: "anthropic"
    base_url: "https://api.anthropic.com"
    api_key: "your-anthropic-api-key-here"
    description: "Anthropic Claude Service"
    is_default: false
    priority: 90
    models:
      - "claude-3-5-sonnet-20241022"
      - "claude-3-opus-20240229"
      - "claude-3-haiku-20240307"

  - name: "google-gemini"
    service_type: "gemini"
    base_url: "https://generativelanguage.googleapis.com/v1beta"
    api_key: "your-google-api-key-here"
    description: "Google Gemini Service"
    is_default: false
    priority: 80  # High priority for Google services
    models:
      # Use alias "gemini-2.5" to randomly select one of the following models
      - "gemini-2.5:gemini-2.0-flash-exp"
      - "gemini-2.5:gemini-exp-1206"
      # You can also define models that can be used directly
      - "gemini-2.0-flash-exp"
      - "gemini-exp-1206"
      - "gemini-1.5-pro"
      - "gemini-1.5-flash"

# Client authentication configuration
client_authentication:
  allowed_keys:
    - "sk-my-secret-key-1"
    - "sk-my-secret-key-2"

# Admin authentication configuration (for web UI)
# Use init_admin.py script to generate hashed password and JWT secret
admin_authentication:
  username: "admin"
  password: "$2b$12$example_hashed_password_here"  # Use init_admin.py to generate
  jwt_secret: "your-secure-random-jwt-secret-min-32-chars"  # Use init_admin.py to generate

# Feature configuration
features:
  enable_function_calling: true  # Enable function calling feature globally (can be overridden per service)
  enable_capability_detection: true  # Enable capability detection API endpoints
  enable_format_conversion: true     # Enable automatic format conversion between OpenAI/Anthropic/Gemini
  log_level: "INFO"              # Logging level: DEBUG, INFO, WARNING, ERROR, CRITICAL, or DISABLED
  convert_developer_to_system: true  # Whether to convert the developer role to the system role
  key_passthrough: false          # If true, directly forward client-provided API key to upstream instead of using configured upstream key
  model_passthrough: false         # If true, forward all requests directly to the 'openai' upstream service, ignoring model-based routing
  
  # Reasoning budget conversion mappings (OpenAI reasoning_effort â†” Anthropic/Gemini thinkingBudget)
  reasoning_budget_mapping:
    openai_to_anthropic:
      low: 2048
      medium: 8192
      high: 16384
    openai_to_gemini:
      low: 2048
      medium: 8192
      high: 16384
    anthropic_to_openai_thresholds:
      low: 2048      # tokens <= 2048 = low
      high: 16384    # tokens >= 16384 = high, otherwise medium
    gemini_to_openai_thresholds:
      low: 2048
      high: 16384
  
  # Custom prompt template (optional). If not provided, the default prompt will be used.
  # The default prompt includes comprehensive features:
  # - Support for multiple tool calls in a single response
  # - Context awareness to avoid duplicate tool calls
  # - Strict parameter matching rules (preserving special characters like hyphens)
  # - Clear format requirements with correct and incorrect examples
  # - Tool result tracking via XML tags
  #
  # You can uncomment and customize the following template if needed:
  # prompt_template: |
  #   Your custom prompt template here...
  #   Must include {tools_list} and {trigger_signal} placeholders

# Configuration explanation:
# 1. upstream_services: Configure multiple OpenAI compatible API services
#    - name: Service name (for identification)
#    - base_url: Base URL of the service
#    - api_key: API key for the corresponding service
#    - models: Complete list of models supported by the service
#    - is_default: Whether it is the default service (used when the requested model is not in any service's model list)
#    - description: Service description (optional)
#
# 2. Routing matching rules:
#    - The system will exactly match the corresponding service based on the model name in the request
#    - If the model name is not in the models list of any service, the service with is_default set to true will be used
#    - There must be one and only one service marked as is_default: true
#
# 3. Client authentication:
#    - allowed_keys: List of client API keys allowed to access this middleware
#
# 4. Logging levels:
#    - DEBUG: Show all debug information (most verbose)
#    - INFO: Show general information, warnings and errors
#    - WARNING: Show only warnings and errors
#    - ERROR: Show only errors
#    - CRITICAL: Show only critical errors
#    - DISABLED: Disable all logging
#
# 5. Security reminders:
#    - Please keep API keys safe and do not commit configuration files containing real keys to version control systems
#    - It is recommended to use different configuration files for different environments
#    - Environment variables can be used to manage sensitive information